{
  "name": "RadAssist — Master Workflow v2",
  "nodes": [
    {
      "id": "b1000001-0001-4000-8000-000000000001",
      "name": "Master Webhook",
      "type": "n8n-nodes-base.webhook",
      "position": [-200, 400],
      "webhookId": "radiology-webhook",
      "parameters": {
        "httpMethod": "POST",
        "path": "radiology",
        "responseMode": "responseNode",
        "options": {},
        "onError": "continueRegularOutput"
      },
      "typeVersion": 2
    },
    {
      "id": "b1000001-0060-4000-8000-000000000001",
      "name": "Check for Image",
      "type": "n8n-nodes-base.if",
      "position": [100, 400],
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": false
          },
          "combinator": "or",
          "conditions": [
            {
              "id": "img-check-1",
              "leftValue": "={{ $json.body.type }}",
              "rightValue": "image_analysis",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ]
        }
      },
      "typeVersion": 2.2
    },
    {
      "id": "b1000001-0060-4000-8000-000000000002",
      "name": "GPT-4o Vision Analysis",
      "type": "n8n-nodes-base.httpRequest",
      "position": [400, -200],
      "parameters": {
        "method": "POST",
        "url": "https://api.openai.com/v1/chat/completions",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "openAiApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({ model: 'gpt-4o', max_tokens: 2000, messages: [{ role: 'system', content: 'You are a medical image analysis specialist. Carefully examine the provided medical image and identify ALL visible findings.\\n\\nINSTRUCTIONS:\\n1. Identify imaging modality, projection/view\\n2. Assess image quality and technical factors\\n3. Systematically examine all anatomical structures region by region\\n4. List ALL normal and abnormal findings with precise anatomical locations\\n5. Note any areas of concern requiring detailed analysis\\n\\nRespond ONLY with valid JSON (no markdown, no code fences):\\n{\\n  \"technical_quality\": \"Image quality and positioning assessment\",\\n  \"findings\": [\"Finding 1 with anatomical location\", \"Finding 2\", ...],\\n  \"preliminary_impression\": \"Initial assessment summary\",\\n  \"areas_of_concern\": [\"Area needing detailed analysis\", ...]\\n}\\n\\nBe thorough — identify EVERY visible finding. Comprehensive clinical correlation and evidence-based reporting using curated medical data will follow.' }, { role: 'user', content: [{ type: 'text', text: 'Analyze this ' + ($json.body.modality || 'X-ray') + ' image of ' + ($json.body.body_part || 'unknown region') + '. Clinical context: ' + ($json.body.clinical_context || 'None provided') + '. Identify all visible findings systematically.' }, { type: 'image_url', image_url: { url: $json.body.image, detail: 'high' } }] }] }) }}",
        "options": {
          "timeout": 60000
        }
      },
      "typeVersion": 4.2
    },
    {
      "id": "b1000001-0060-4000-8000-000000000003",
      "name": "Parse Vision Findings",
      "type": "n8n-nodes-base.code",
      "position": [700, -200],
      "parameters": {
        "jsCode": "const response = $input.first().json;\nconst content = response.choices?.[0]?.message?.content || '';\n\n// Get original request data from webhook\nlet originalBody = {};\ntry {\n  originalBody = $('Master Webhook').first().json.body || {};\n} catch (e) {\n  originalBody = {};\n}\n\nlet visionData = {\n  technical_quality: '',\n  findings: [],\n  preliminary_impression: '',\n  areas_of_concern: []\n};\n\ntry {\n  const jsonMatch = content.match(/\\{[\\s\\S]*\\}/);\n  if (jsonMatch) {\n    visionData = JSON.parse(jsonMatch[0]);\n  }\n} catch (e) {}\n\n// Build findings text for the agent\nconst findingsText = Array.isArray(visionData.findings)\n  ? visionData.findings.map((f, i) => `${i + 1}. ${f}`).join('\\n')\n  : String(visionData.findings || content);\n\nconst concernsText = Array.isArray(visionData.areas_of_concern)\n  ? visionData.areas_of_concern.join(', ')\n  : String(visionData.areas_of_concern || '');\n\nreturn [{\n  json: {\n    vision_analysis: content,\n    technical_quality: visionData.technical_quality || '',\n    findings_text: findingsText,\n    preliminary_impression: visionData.preliminary_impression || '',\n    areas_of_concern: concernsText,\n    modality: originalBody.modality || 'xray',\n    body_part: originalBody.body_part || '',\n    clinical_context: originalBody.clinical_context || ''\n  }\n}];"
      },
      "typeVersion": 2
    },

    {
      "id": "d3000001-0001-4000-8000-000000000001",
      "name": "Image Report Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [1000, -200],
      "parameters": {
        "promptType": "define",
        "text": "=Medical image analysis — {{ $json.modality || 'X-ray' }} of {{ $json.body_part || 'unknown region' }}\n\nTechnical Quality: {{ $json.technical_quality || 'Not assessed' }}\n\nVision Findings:\n{{ $json.findings_text || 'No findings extracted' }}\n\nPreliminary Impression: {{ $json.preliminary_impression || 'Not available' }}\n\nAreas of Concern: {{ $json.areas_of_concern || 'None specified' }}\n\nClinical Context: {{ $json.clinical_context || 'None provided' }}\n\nINSTRUCTIONS:\nStep 1: Search the Radiology Knowledge Base (Pinecone) for EACH identified finding. Look up pathology descriptions, differential diagnoses, diagnostic criteria, imaging characteristics, and clinical significance.\nStep 2: Use Perplexity Web Search to verify clinical accuracy, find latest guidelines, or get additional context for significant or complex findings.\nStep 3: Synthesize the vision findings with curated knowledge base data and supplementary research into a comprehensive, precise, evidence-backed medical radiology report.\n\nYour response MUST be a valid JSON object (no markdown, no code fences):\n{\n  \"report\": \"EXAM: [modality] [body part]\\n\\nCLINICAL INDICATION: [context]\\n\\nTECHNIQUE: [view/projection]\\n\\nCOMPARISON: None available.\\n\\nFINDINGS:\\n[Detailed systematic description with clinical correlation from knowledge base]\\n\\nIMPRESSION:\\n1. [Most significant finding with evidence-based assessment]\\n2. [Secondary findings]\",\n  \"findings\": [\"Finding 1 with clinical significance from KB\", \"Finding 2\"],\n  \"impression\": \"Evidence-based clinical impression with differential diagnoses ranked by probability\",\n  \"recommendations\": \"Guideline-based follow-up recommendations\",\n  \"sources\": \"pinecone\" or \"pinecone+perplexity\"\n}",
        "options": {
          "systemMessage": "You are RadAssist, an expert AI radiology reporting system that produces comprehensive, precise medical radiology reports backed by curated medical data.\n\nDATA SOURCE PRIORITY:\n1. PRIMARY: Always search the Radiology Knowledge Base (Pinecone) FIRST for EVERY finding identified in the image. This contains 3,281 curated, verified radiology documents covering pathologies, anatomy, diagnostic criteria, report templates, and clinical guidelines.\n2. SUPPLEMENTARY: Use Perplexity Web Search when:\n   - The knowledge base has limited information on a finding\n   - You need to verify or cross-reference diagnoses\n   - Latest clinical guidelines or research are relevant\n   - Additional clinical context would strengthen the report\n\nCRITICAL RULES:\n- NEVER rely solely on general AI knowledge — always back findings with curated data from your tools\n- Search Pinecone for EACH individual finding, not just one general search\n- Use precise medical terminology (ACR/RSNA standard)\n- Include evidence-based differential diagnoses ranked by probability\n- Reference established diagnostic criteria when applicable (e.g., Fleischner criteria for pulmonary nodules, BI-RADS for breast imaging)\n- Recommendations must be specific, guideline-based, and clinically actionable\n- Include clinical correlation with patient history when available\n\nREPORT QUALITY:\n- Systematic region-by-region description\n- Specific measurements and descriptions where applicable\n- Normal structures explicitly stated as normal\n- Abnormalities described with size, location, morphology, and clinical significance\n- Impression summarizes key findings with confidence levels\n\nYour response MUST be a valid JSON object with: report, findings[], impression, recommendations, sources\n\nDISCLAIMER: Always note that this is AI-assisted analysis for educational purposes requiring verification by a qualified radiologist."
        }
      },
      "typeVersion": 1.9
    },
    {
      "id": "d3000001-0001-4000-8000-000000000002",
      "name": "GPT-4o (Image Report)",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [900, -440],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4o"
        },
        "options": {}
      },
      "typeVersion": 1.2
    },
    {
      "id": "d3000001-0001-4000-8000-000000000003",
      "name": "Image Knowledge Base",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "position": [1100, -440],
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolName": "radiology_image_knowledge_base",
        "toolDescription": "PRIMARY data source for image analysis. Search the curated radiology knowledge base containing 3,281 documents of medical imaging findings, pathology descriptions, diagnostic criteria, anatomy references, and clinical guidelines. Search this FIRST for every finding identified in the image. Use specific finding names as search queries.",
        "pineconeIndex": {
          "__rl": true,
          "mode": "list",
          "value": "radiology-assistant",
          "cachedResultName": "radiology-assistant"
        },
        "topK": 10,
        "options": {}
      },
      "typeVersion": 1.3
    },
    {
      "id": "d3000001-0001-4000-8000-000000000004",
      "name": "Image Embeddings",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "position": [1100, -640],
      "parameters": {
        "model": "text-embedding-3-small",
        "options": {}
      },
      "typeVersion": 1.2
    },
    {
      "id": "d3000001-0001-4000-8000-000000000005",
      "name": "Perplexity Search (Image)",
      "type": "n8n-nodes-base.perplexityTool",
      "position": [1300, -440],
      "parameters": {
        "model": "sonar-pro",
        "messages": {
          "message": [
            {
              "content": "You are a medical imaging research assistant. Search for the latest peer-reviewed radiology findings, diagnostic criteria, clinical guidelines, and evidence-based imaging interpretations. Provide clinically accurate, well-cited responses.",
              "role": "system"
            },
            {
              "content": "={{ $fromAI('query', 'The specific radiology finding or clinical question to research for the image analysis report') }}",
              "role": "user"
            }
          ]
        }
      },
      "typeVersion": 1
    },
    {
      "id": "d3000001-0001-4000-8000-000000000006",
      "name": "Compile Image Report",
      "type": "n8n-nodes-base.code",
      "position": [1300, -200],
      "parameters": {
        "jsCode": "const agentOutput = $input.first().json;\nconst content = agentOutput.output || agentOutput.text || '';\n\ntry {\n  const textToParse = content || JSON.stringify(agentOutput);\n  const jsonMatch = textToParse.match(/\\{[\\s\\S]*\\}/);\n  if (jsonMatch) {\n    const parsed = JSON.parse(jsonMatch[0]);\n    return [{\n      json: {\n        type: 'image_analysis',\n        report: parsed.report || textToParse,\n        findings: Array.isArray(parsed.findings) ? parsed.findings : [],\n        impression: parsed.impression || '',\n        recommendations: parsed.recommendations || '',\n        sources: parsed.sources || 'pinecone'\n      }\n    }];\n  }\n} catch (e) {}\n\nreturn [{\n  json: {\n    type: 'image_analysis',\n    report: content || JSON.stringify(agentOutput, null, 2),\n    findings: [],\n    impression: '',\n    recommendations: '',\n    sources: 'unknown'\n  }\n}];"
      },
      "typeVersion": 2
    },

    {
      "id": "b1000001-0002-4000-8000-000000000001",
      "name": "Route Request",
      "type": "@n8n/n8n-nodes-langchain.textClassifier",
      "position": [400, 400],
      "parameters": {
        "inputText": "={{ $json.body.message || $json.body.query || $json.body.term || '' }}",
        "categories": {
          "categories": [
            {
              "category": "Radiology Chat",
              "description": "User is asking a medical or radiology question, seeking information about imaging findings, pathologies, differentials, clinical conditions, or looking up a specific radiology or medical term. Includes questions, search queries, simple term lookups, and clinical correlation requests."
            },
            {
              "category": "Report Generation",
              "description": "User explicitly wants to generate, create, or write a structured radiology report. They provide specific imaging findings, modality, body part, and/or clinical history. The request is specifically about producing a formatted medical report document."
            }
          ]
        },
        "options": {
          "fallback": "other"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "b1000001-0002-4000-8000-000000000002",
      "name": "Classifier Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [340, 640],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4o-mini"
        },
        "options": {}
      },
      "typeVersion": 1.2
    },

    {
      "id": "c2000001-0001-4000-8000-000000000001",
      "name": "Chat Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [800, 200],
      "parameters": {
        "promptType": "define",
        "text": "=Radiology question: {{ $json.body.message || $json.body.query || $json.body.term }}\n\nFilters:\n- Modality: {{ $json.body.modality || 'all' }}\n- Body System: {{ $json.body.system || 'all' }}\n\nStep 1: Search the Radiology Knowledge Base (Pinecone) for curated, precise information.\nStep 2: If the knowledge base provides limited or incomplete information, use Perplexity Web Search to find additional context, latest research, or verification.\nStep 3: Synthesize both sources into a comprehensive response. Always prioritize Pinecone data as the primary source.",
        "options": {
          "systemMessage": "You are RadAssist, an expert AI radiology assistant.\n\nDATA SOURCE PRIORITY:\n1. PRIMARY: Always search the Radiology Knowledge Base (Pinecone) FIRST. This contains curated, verified radiology data (3,281 documents).\n2. SUPPLEMENTARY: Use Perplexity Web Search ONLY when:\n   - The knowledge base has limited information on the topic\n   - You need to verify or cross-reference findings\n   - The user asks about very recent research or guidelines\n   - Additional clinical context would be valuable\n\nRESPONSE FORMAT - Your response MUST be a valid JSON object (no markdown, no code fences):\n{\n  \"keywords\": [\"relevant\", \"radiology\", \"terms\"],\n  \"findings\": \"Detailed description of key imaging findings\",\n  \"differentials\": [\"Most likely diagnosis\", \"Second most likely\", \"Third\"],\n  \"report_suggestion\": \"Suggested radiology report language\",\n  \"sources\": \"pinecone\" or \"pinecone+perplexity\"\n}\n\nGuidelines:\n- Keywords: 3-8 relevant radiology terms\n- Findings: describe imaging characteristics, patterns, and clinical significance\n- Differentials: ordered by likelihood, include 3-6 options\n- Report suggestion: use RSNA-style radiology language\n- Sources: indicate which data sources contributed to the response\n- ONLY output the raw JSON object, nothing else"
        }
      },
      "typeVersion": 1.9
    },
    {
      "id": "c2000001-0001-4000-8000-000000000002",
      "name": "GPT-4o (Chat)",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [700, 460],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4o"
        },
        "options": {}
      },
      "typeVersion": 1.2
    },
    {
      "id": "c2000001-0001-4000-8000-000000000003",
      "name": "Chat Knowledge Base",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "position": [920, 460],
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolName": "radiology_knowledge_base",
        "toolDescription": "PRIMARY data source. Search the curated radiology knowledge base containing 3,281 documents of medical imaging information, pathology descriptions, anatomy references, report templates, and clinical guidelines. Always search this FIRST before using other tools.",
        "pineconeIndex": {
          "__rl": true,
          "mode": "list",
          "value": "radiology-assistant",
          "cachedResultName": "radiology-assistant"
        },
        "topK": 8,
        "options": {}
      },
      "typeVersion": 1.3
    },
    {
      "id": "c2000001-0001-4000-8000-000000000004",
      "name": "Chat Embeddings",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "position": [920, 680],
      "parameters": {
        "model": "text-embedding-3-small",
        "options": {}
      },
      "typeVersion": 1.2
    },
    {
      "id": "c2000001-0001-4000-8000-000000000005",
      "name": "Perplexity Search (Chat)",
      "type": "n8n-nodes-base.perplexityTool",
      "position": [1140, 460],
      "parameters": {
        "model": "sonar-pro",
        "messages": {
          "message": [
            {
              "content": "You are a medical research assistant. Search for the latest peer-reviewed radiology and medical imaging information. Provide evidence-based, clinically accurate responses with citations when available.",
              "role": "system"
            },
            {
              "content": "={{ $fromAI('query', 'The radiology search query for supplementary information') }}",
              "role": "user"
            }
          ]
        }
      },
      "typeVersion": 1
    },
    {
      "id": "c2000001-0001-4000-8000-000000000006",
      "name": "Format Chat Response",
      "type": "n8n-nodes-base.code",
      "position": [1200, 200],
      "parameters": {
        "jsCode": "const output = $input.first().json.output || $input.first().json.text || '';\n\ntry {\n  const jsonMatch = output.match(/\\{[\\s\\S]*\\}/);\n  if (jsonMatch) {\n    const parsed = JSON.parse(jsonMatch[0]);\n    return [{\n      json: {\n        type: 'chat',\n        keywords: parsed.keywords || [],\n        findings: parsed.findings || '',\n        differentials: parsed.differentials || [],\n        report_suggestion: parsed.report_suggestion || '',\n        sources: parsed.sources || 'pinecone'\n      }\n    }];\n  }\n} catch (e) {}\n\nreturn [{\n  json: {\n    type: 'chat',\n    keywords: [],\n    findings: output,\n    differentials: [],\n    report_suggestion: '',\n    sources: 'pinecone'\n  }\n}];"
      },
      "typeVersion": 2
    },

    {
      "id": "b1000001-0020-4000-8000-000000000001",
      "name": "Report Agent",
      "type": "@n8n/n8n-nodes-langchain.agent",
      "position": [800, 600],
      "parameters": {
        "promptType": "define",
        "text": "=Generate a structured radiology report:\n\nModality: {{ $json.body.modality || 'X-ray' }}\nBody Part: {{ $json.body.body_part || 'Chest' }}\nClinical History: {{ $json.body.clinical_history || 'Not provided' }}\n\nFindings:\n{{ $json.body.findings ? $json.body.findings.join('\\n- ') : $json.body.message || 'None specified' }}\n\nStep 1: Search the Radiology Knowledge Base for report templates and medical context.\nStep 2: If needed, use Perplexity to verify clinical accuracy or find additional relevant guidelines.\nStep 3: Generate the complete report prioritizing curated knowledge base data.",
        "options": {
          "systemMessage": "You are RadAssist Report Generator. Generate professional, structured radiology reports following RSNA standards.\n\nDATA SOURCE PRIORITY:\n1. PRIMARY: Always search the Report Knowledge Base (Pinecone) FIRST for templates and clinical data.\n2. SUPPLEMENTARY: Use Perplexity Web Search ONLY when additional clinical accuracy verification is needed or for latest reporting guidelines.\n\nYour response MUST be a valid JSON object (no markdown, no code fences, just raw JSON):\n{\n  \"report\": \"EXAM: [Modality] [Body Part]\\n\\nCLINICAL INDICATION: [History]\\n\\nTECHNIQUE: [Technique]\\n\\nCOMPARISON: None available.\\n\\nFINDINGS:\\n[Organized by structure]\\n\\nIMPRESSION:\\n1. [Key finding]\\n2. [Secondary finding]\"\n}\n\nGuidelines:\n- Use standard radiology terminology\n- Be systematic and thorough\n- Prioritize urgent findings\n- Include follow-up recommendations when appropriate\n- ONLY output the raw JSON object"
        }
      },
      "typeVersion": 1.9
    },
    {
      "id": "b1000001-0020-4000-8000-000000000002",
      "name": "GPT-4o (Report)",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenAi",
      "position": [700, 860],
      "parameters": {
        "model": {
          "__rl": true,
          "mode": "list",
          "value": "gpt-4o"
        },
        "options": {}
      },
      "typeVersion": 1.2
    },
    {
      "id": "b1000001-0020-4000-8000-000000000003",
      "name": "Report Knowledge Base",
      "type": "@n8n/n8n-nodes-langchain.vectorStorePinecone",
      "position": [920, 860],
      "parameters": {
        "mode": "retrieve-as-tool",
        "toolName": "report_knowledge_base",
        "toolDescription": "PRIMARY data source. Search the radiology knowledge base for report templates, standard findings descriptions, and clinical guidelines for the given modality and body part. Always search this FIRST.",
        "pineconeIndex": {
          "__rl": true,
          "mode": "list",
          "value": "radiology-assistant",
          "cachedResultName": "radiology-assistant"
        },
        "topK": 6,
        "options": {}
      },
      "typeVersion": 1.3
    },
    {
      "id": "b1000001-0020-4000-8000-000000000004",
      "name": "Report Embeddings",
      "type": "@n8n/n8n-nodes-langchain.embeddingsOpenAi",
      "position": [920, 1080],
      "parameters": {
        "model": "text-embedding-3-small",
        "options": {}
      },
      "typeVersion": 1.2
    },
    {
      "id": "c2000001-0002-4000-8000-000000000005",
      "name": "Perplexity Search (Report)",
      "type": "n8n-nodes-base.perplexityTool",
      "position": [1140, 860],
      "parameters": {
        "model": "sonar-pro",
        "messages": {
          "message": [
            {
              "content": "You are a medical reporting assistant. Search for radiology report guidelines, RSNA standards, and clinical best practices for report writing.",
              "role": "system"
            },
            {
              "content": "={{ $fromAI('query', 'The search query for report generation context') }}",
              "role": "user"
            }
          ]
        }
      },
      "typeVersion": 1
    },
    {
      "id": "b1000001-0020-4000-8000-000000000005",
      "name": "Format Report Response",
      "type": "n8n-nodes-base.code",
      "position": [1200, 600],
      "parameters": {
        "jsCode": "const output = $input.first().json.output || $input.first().json.text || '';\n\ntry {\n  const jsonMatch = output.match(/\\{[\\s\\S]*\\}/);\n  if (jsonMatch) {\n    const parsed = JSON.parse(jsonMatch[0]);\n    return [{ json: { type: 'report', report: parsed.report || output } }];\n  }\n} catch (e) {}\n\nreturn [{ json: { type: 'report', report: output } }];"
      },
      "typeVersion": 2
    },

    {
      "id": "b1000001-0040-4000-8000-000000000001",
      "name": "Format Error Response",
      "type": "n8n-nodes-base.code",
      "position": [800, 1100],
      "parameters": {
        "jsCode": "return [{\n  json: {\n    type: 'error',\n    message: 'Your request could not be classified. Please try rephrasing as a radiology question, report request, or term lookup.',\n    received: $input.first().json.body?.message || $input.first().json.body?.query || $input.first().json.body?.term || ''\n  }\n}];"
      },
      "typeVersion": 2
    },

    {
      "id": "b1000001-0050-4000-8000-000000000001",
      "name": "Send Response",
      "type": "n8n-nodes-base.respondToWebhook",
      "position": [1600, 500],
      "parameters": {
        "respondWith": "firstIncomingItem",
        "options": {}
      },
      "typeVersion": 1.5
    },

    {
      "id": "b1000001-9001-4000-8000-000000000001",
      "name": "RadAssist Overview",
      "type": "n8n-nodes-base.stickyNote",
      "position": [-500, -100],
      "parameters": {
        "width": 420,
        "height": 720,
        "content": "## RadAssist v2.1 — Enhanced Image Analysis\n\n**Single Endpoint Architecture**\nPOST /webhook/radiology\n\n### Flow:\n1. Master Webhook receives ALL requests\n2. IF check: image present? → Two-Step Vision Pipeline\n3. Else: Text Classifier routes to branch\n4. Single Send Response returns result\n\n### 3 Branches:\n- **Image Analysis** → GPT-4o Vision (extract findings) → AI Agent (Pinecone + Perplexity enrichment) → Comprehensive Report\n- **Chat** → Unified AI Agent (Pinecone PRIMARY + Perplexity SUPPLEMENTARY)\n- **Report** → Report AI Agent (Pinecone PRIMARY + Perplexity SUPPLEMENTARY)\n- **Fallback** → Error message\n\n### Data Sources (ALL branches):\n- Pinecone: 3,281 curated radiology vectors (PRIMARY)\n- Perplexity sonar-pro: External web search (SUPPLEMENTARY)\n\n### Request Body:\n{ message, type?, image?, modality?, system?, findings?, body_part?, term?, clinical_context? }\n\n### Setup:\n1. Add OpenAI credentials\n2. Add Pinecone credentials\n3. Add Perplexity credentials\n4. Activate workflow"
      },
      "typeVersion": 1
    },
    {
      "id": "b1000001-9002-4000-8000-000000000001",
      "name": "Classifier",
      "type": "n8n-nodes-base.stickyNote",
      "position": [200, 300],
      "parameters": {
        "width": 360,
        "height": 420,
        "content": "### Text Classifier\nGPT-4o-mini classifies incoming message:\n- Output 0: Radiology Chat (queries + lookups)\n- Output 1: Report Generation\n- Output 2: Other (fallback)"
      },
      "typeVersion": 1
    },
    {
      "id": "b1000001-9006-4000-8000-000000000001",
      "name": "Image Analysis Branch",
      "type": "n8n-nodes-base.stickyNote",
      "position": [220, -720],
      "parameters": {
        "width": 1200,
        "height": 300,
        "content": "### Branch 0: Image Analysis — Two-Step Pipeline\n\n**Step 1: Vision** → GPT-4o Vision extracts all visible findings from the image\n**Step 2: Agent** → AI Agent enriches findings with:\n  - Pinecone KB (PRIMARY, topK=10) — curated 3,281 radiology vectors\n  - Perplexity sonar-pro (SUPPLEMENTARY) — clinical verification\n\nReturns: { type, report, findings[], impression, recommendations, sources }\n\nThis produces comprehensive, evidence-backed medical reports — not generic AI output."
      },
      "typeVersion": 1
    },
    {
      "id": "c2000001-9003-4000-8000-000000000001",
      "name": "Chat Branch",
      "type": "n8n-nodes-base.stickyNote",
      "position": [620, 100],
      "parameters": {
        "width": 700,
        "height": 640,
        "content": "### Branch 1: Radiology Chat (Unified)\nAI Agent with dual data sources:\n- Pinecone (PRIMARY) — curated 3,281 vectors\n- Perplexity sonar-pro (SUPPLEMENTARY) — external verification\nReturns: { type, keywords, findings, differentials, report_suggestion, sources }"
      },
      "typeVersion": 1
    },
    {
      "id": "b1000001-9004-4000-8000-000000000001",
      "name": "Report Branch",
      "type": "n8n-nodes-base.stickyNote",
      "position": [620, 500],
      "parameters": {
        "width": 700,
        "height": 640,
        "content": "### Branch 2: Report Generator\nAI Agent with dual data sources:\n- Pinecone (PRIMARY) — report templates & clinical data\n- Perplexity sonar-pro (SUPPLEMENTARY) — accuracy verification\nReturns: { type, report }"
      },
      "typeVersion": 1
    }
  ],
  "connections": {
    "Master Webhook": {
      "main": [
        [
          {
            "node": "Check for Image",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check for Image": {
      "main": [
        [
          {
            "node": "GPT-4o Vision Analysis",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Route Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GPT-4o Vision Analysis": {
      "main": [
        [
          {
            "node": "Parse Vision Findings",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Vision Findings": {
      "main": [
        [
          {
            "node": "Image Report Agent",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "GPT-4o (Image Report)": {
      "ai_languageModel": [
        [
          {
            "node": "Image Report Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Image Knowledge Base": {
      "ai_tool": [
        [
          {
            "node": "Image Report Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Image Embeddings": {
      "ai_embedding": [
        [
          {
            "node": "Image Knowledge Base",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Perplexity Search (Image)": {
      "ai_tool": [
        [
          {
            "node": "Image Report Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Image Report Agent": {
      "main": [
        [
          {
            "node": "Compile Image Report",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Compile Image Report": {
      "main": [
        [
          {
            "node": "Send Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },

    "Classifier Model": {
      "ai_languageModel": [
        [
          {
            "node": "Route Request",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Route Request": {
      "main": [
        [
          {
            "node": "Chat Agent",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Report Agent",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Format Error Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },

    "GPT-4o (Chat)": {
      "ai_languageModel": [
        [
          {
            "node": "Chat Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Chat Knowledge Base": {
      "ai_tool": [
        [
          {
            "node": "Chat Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Chat Embeddings": {
      "ai_embedding": [
        [
          {
            "node": "Chat Knowledge Base",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Perplexity Search (Chat)": {
      "ai_tool": [
        [
          {
            "node": "Chat Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Chat Agent": {
      "main": [
        [
          {
            "node": "Format Chat Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Chat Response": {
      "main": [
        [
          {
            "node": "Send Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },

    "GPT-4o (Report)": {
      "ai_languageModel": [
        [
          {
            "node": "Report Agent",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Report Knowledge Base": {
      "ai_tool": [
        [
          {
            "node": "Report Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Report Embeddings": {
      "ai_embedding": [
        [
          {
            "node": "Report Knowledge Base",
            "type": "ai_embedding",
            "index": 0
          }
        ]
      ]
    },
    "Perplexity Search (Report)": {
      "ai_tool": [
        [
          {
            "node": "Report Agent",
            "type": "ai_tool",
            "index": 0
          }
        ]
      ]
    },
    "Report Agent": {
      "main": [
        [
          {
            "node": "Format Report Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Report Response": {
      "main": [
        [
          {
            "node": "Send Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },

    "Format Error Response": {
      "main": [
        [
          {
            "node": "Send Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "active": false
}